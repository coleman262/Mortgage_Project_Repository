import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sqlalchemy import create_engine
import matplotlib.pyplot as plt


# Time2Vec Class
class Time2Vec(nn.Module):
    def __init__(self, kernel_size=1):
        super(Time2Vec, self).__init__()
        self.kernel_size = kernel_size
        self.wb = nn.Linear(1, 1)  # Linear component
        self.bb = nn.Parameter(torch.zeros(1))
        self.wa = nn.Linear(1, kernel_size - 1)  # Periodic component
        self.ba = nn.Parameter(torch.zeros(kernel_size - 1))

    def forward(self, x):
        linear = self.wb(x) + self.bb
        sin_trans = torch.sin(self.wa(x) + self.ba)
        return torch.cat([linear, sin_trans], -1)


# Modified FinancialDataset Class
class FinancialDataset(Dataset):
    def __init__(self, data, sequence_length=180, prediction_length=20, time2vec_dim=2):
        self.data = data
        self.sequence_length = sequence_length
        self.prediction_length = prediction_length
        self.time2vec = Time2Vec(time2vec_dim)

    def __len__(self):
        return len(self.data) - self.sequence_length - self.prediction_length

    def __getitem__(self, idx):
        time_feature = torch.Tensor(self.data.iloc[idx:idx + self.sequence_length][['index']].values.astype(np.float32))
        time_encoded = self.time2vec(time_feature)
        X = torch.cat((time_encoded, torch.Tensor(
            self.data.iloc[idx:idx + self.sequence_length][['dgs10']].values.astype(np.float32))), dim=1)
        y = torch.Tensor(self.data.iloc[idx + self.sequence_length:idx + self.sequence_length + self.prediction_length][
                             ['dgs10']].values.astype(np.float32))
        return X, y.squeeze(1)


# Modified EnhancedRNN Class
class EnhancedRNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, prediction_length, time2vec_dim=10, num_layers=2, dropout=0.5):
        super(EnhancedRNN, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_dim, prediction_length)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])  # Last time step's output
        return out


# Database connection parameters
# Database connection parameters
db_host = 'localhost'
db_name = 'postgres'
db_user = 'postgres'
db_password = 'password123$'
table_name = 'model_data_daily'

# Database connection URL
db_url = f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}/{db_name}'

# Create a SQLAlchemy engine
engine = create_engine(db_url)

# SQL query and data processing
try:
    # SQL query
    sql_query = f"""
        SELECT "index", "dgs10"
        FROM {table_name}
        ORDER BY "index";
    """

    data = pd.read_sql_query(sql_query, engine)
    print(data.columns)

    if len(data) == 0:
        raise Exception("No data fetched from the database")

    # Preserve original dates for plotting
    data['date'] = pd.to_datetime(data['index'])
    # Convert 'index' from date to timestamp for model processing
    data['index'] = data['date'].astype(np.int64) // 10 ** 9
    data['index'] = (data['index'] - data['index'].min()) / (60 * 60 * 24)  # Convert to days

    scaler = StandardScaler()
    data['dgs10'] = scaler.fit_transform(data['dgs10'].values.reshape(-1, 1)).flatten()

    split_ratio = 0.8
    split_idx = int(len(data) * split_ratio)
    train_data = data.iloc[:split_idx]
    test_data = data.iloc[split_idx:]

    sequence_length = 30
    prediction_length = 20
    time2vec_dim = 10

    # Correct calculation of input dimension
    input_dim = 1 + time2vec_dim  # Assuming 'dgs10' is the only feature besides 'index'

    # Define the hidden dimension for the RNN
    hidden_dim = 64

    train_dataset = FinancialDataset(train_data, sequence_length, prediction_length, time2vec_dim)
    test_dataset = FinancialDataset(test_data, sequence_length, prediction_length, time2vec_dim)

    batch_size = 32
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    model = EnhancedRNN(input_dim, hidden_dim, prediction_length, time2vec_dim)

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    num_epochs = 50
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        for batch_x, batch_y in train_loader:
            optimizer.zero_grad()
            output = model(batch_x)
            loss = criterion(output, batch_y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')

    # Prediction code for future periods
    model.eval()
    with torch.no_grad():
        # Extract the last sequence of data
        last_sequence = test_data.iloc[-sequence_length:]

        # Prepare the sequence for the model
        time_feature = torch.Tensor(last_sequence[['index']].values.astype(np.float32))
        time_encoded = train_dataset.time2vec(time_feature)
        last_sequence_X = torch.cat((time_encoded, torch.Tensor(last_sequence[['dgs10']].values.astype(np.float32))),
                                    dim=1)

        # Reshape to match batch size of 1
        last_sequence_X = last_sequence_X.unsqueeze(0)

        # Ensure that last_sequence_X has the correct shape
        if last_sequence_X.shape[1] != sequence_length:
            raise ValueError("The shape of the last_sequence_X is incorrect. Expected sequence_length in dimension 1.")

        # Predicting forward
        output = model(last_sequence_X)
        original_predictions = scaler.inverse_transform(output.numpy()).flatten()

        # Generating future dates
        last_date = pd.to_datetime(last_sequence['date'].iloc[-1])
        future_dates = [last_date + pd.Timedelta(days=i) for i in range(1, prediction_length + 1)]

        # Creating DataFrame for the predictions
        future_prediction_df = pd.DataFrame({'Date': future_dates, 'Predicted_dgs10': original_predictions})
        print("Future Predictions:")
        print(future_prediction_df)

        # Optionally, you can save this dataframe to a CSV file or plot it
        #future_prediction_df.to_csv("C:\Users\colem\future_predictions.csv", index=False)

        # If you want to plot, uncomment the below lines
        plt.figure(figsize=(12, 6))
        plt.plot(future_dates, original_predictions, label='Future Projections', color='green')
        plt.xlabel('Date')
        plt.ylabel('dgs10')
        plt.title('Model Future Projections')
        plt.legend()
        plt.grid(True)
        plt.show()

except Exception as e:
    print("Error: Unable to fetch data from the database or preprocess data")
    print(e)
finally:
    engine.dispose()  # Close the database connection
